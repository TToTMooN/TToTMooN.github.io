# jemdoc: menu{MENU}{index.html}, nofooter  
==Lingfeng Sun 

~~~
{}{img_left}{imgs/lingfeng.jpg}{alt text}{}{200}{}
Ph.D. Candidate,\n 
[https://msc.berkeley.edu/index.html Mechanical System Control Lab], \n
[https://www.berkeley.edu/ UC Berkeley]\n

Email: /lingfengsun/ \[AT\] berkeley \[DOT\] edu  

 [https://scholar.google.com/citations?user=Uxb6wbkAAAAJ&hl=en&oi=ao Google Scholar] / [files/LingfengSun_CV.pdf CV]
~~~

== About me
I am a final year PhD student in robotics at [https://www.berkeley.edu/ University of California, Berkeley] adviced by [https://me.berkeley.edu/people/masayoshi-tomizuka/ Prof. Masayoshi Tomizuka].
I received B.S. in Mechanical Engineering from [https://umich.edu/ University of Michigan, Ann Arbor], 
and B.S. in Electrical and Computer Engineering from [http://ji.sjtu.edu.cn/ Joint Institute, Shanghai Jiao Tong University].

My research interest lies in *Robotics* (skill learning, control and planning) and *Autonomous driving* (interaction generation, behavior prediction).

I'm joining [https://theaiinstitute.com/ Boston Dynamics AI Institute] as a Research Scientist in June, 2024.

== Experience
Research Intern,  [https://www.merl.com/ Mitsubishi Electrical Research Laboratories], 05\/2023 - 09\/2023\n

AI Resident, [https://everydayrobots.com/ Everyday Robots (Google X)], 05\/2022 - 12\/2022

Research Intern, [https://en.horizon.cc/ Horizon Robotics], 05\/2021 - 04\/2022

== Teaching
Graduate Student Instructor, *ME 232 Advanced Control Systems I*, UC Berkeley, Fall 2022\n
Graduate Student Instructor, *ME 233 Advanced Control Systems II*, UC Berkeley, Spring 2024\n


== Selected Research 
~~~
{}{raw}
<h3 class="collapsible"> Robot Skill Learning [-]</h3>
<div class="content" style="display:block;">
~~~

~~~
{}{img_left}{imgs/efficient-locomotion.gif}{alt text}{250}{}{index.html}
[https://sites.google.com/berkeley.edu/efficient-locomotion Adaptive Energy Regularization for Autonomous Gait Transition and Energy-Efficient Quadruped Locomotion]\n
*Lingfeng Sun\**, Boyuan Liang\*, Xinghao Zhu\*, Bike Zhang, Koushil Sreenath, Masayoshi Tomizuka \n
/in submission/ \n
[https://sites.google.com/berkeley.edu/efficient-locomotion \[Website\]]
[https://https://arxiv.org/abs/2403.20001 \[Paper\]]
~~~

~~~
{}{img_left}{imgs/llm.png}{alt text}{250}{}{}
[https://arxiv.org/abs/2312.06876 LLM-POP: Large Language Model for Partially Observable Task Planning]\n
*Lingfeng Sun*, Devesh K. Jha, Chiori Hori, Siddarth Jain, Radu Corcodel, Xinghao Zhu, Masayoshi Tomizuka, Diego Romeres \n
/ICRA 2024/ \n
/*Honorable Mention*, [https://an-instructive-workshop.github.io/ Workshop on Instruction Tuning and Instruction Following], NeurIPS 2023/ \n
[https://arxiv.org/abs/2312.06876 \[Paper\]]
~~~

~~~
{}{img_left}{imgs/mtrl.gif}{alt text}{250}{}{https://sites.google.com/berkeley.edu/distributed-interaction/}
[https://proceedings.neurips.cc/paper_files/paper/2022/file/86b8ad667206fb9a52ae575fbf1cd6be-Paper-Conference.pdf PaCo: Parameter-Compositional Multi-Task Reinforcement Learning]\n
*Lingfeng Sun\**, Haichao Zhang\*, Wei Xu, Masayoshi Tomizuka \n
/NeurIPS 2022/ \n
[https://sites.google.com/site/hczhang1/projects/paco-mtrl \[Website\]]
[https://proceedings.neurips.cc/paper_files/paper/2022/file/86b8ad667206fb9a52ae575fbf1cd6be-Paper-Conference.pdf \[Paper\]]
[https://github.com/TToTMooN/paco-mtrl \[Code\]]
~~~

~~~
{}{img_left}{imgs/taco.png}{alt text}{250}{}{https://arxiv.org/pdf/2306.01839}
[https://arxiv.org/pdf/2306.01839 Efficient Multi-Task and Transfer Reinforcement Learning with Parameter-Compositional Framework]\n
*Lingfeng Sun\**, Haichao Zhang\*, Wei Xu, Masayoshi Tomizuka \n
/Robotics and Automation Letters/ \n
[https://arxiv.org/pdf/2306.01839 \[Paper]]
~~~

~~~
{}{img_left}{imgs/assembly.gif}{alt text}{250}{}{}
[https://arxiv.org/abs/2312.10571 Multi-level Reasoning for Robotic Assembly: From Sequence Inference to Contact Selection]\n
Xinghao Zhu, Devesh K. Jha, Diego Romeres, *Lingfeng Sun*, Masayoshi Tomizuka, Anoop Cherian \n
/ICRA 2024/ \n
[https://arxiv.org/abs/2312.10571 \[Paper\]]
~~~

~~~
{}{img_left}{imgs/admitlearn.gif}{alt text}{250}{}{https://sites.google.com/view/admitlearn }
[papers/2023_distributed_ipg.pdf Efficient Sim-to-real Transfer of Contact-Rich Manipulation Skills with Online Admittance Residual Learning]\n
Xiang Zhang\*, Changhao Wang\*, *Lingfeng Sun*, Zheng Wu, Xinghao Zhu, Masayoshi Tomizuka \n
/CoRL 2023/ \n
[https://sites.google.com/view/admitlearn \[Website\]]
[https://openreview.net/pdf?id=gFXVysXh48K \[Paper]]
~~~

{{</div>}}

~~~
{}{raw}
<h3 class="collapsible"> Multi-agent Interaction Generation [-]</h3>
<div class="content" style="display:block;">
~~~

~~~
{}{img_left}{imgs/ipg.gif}{alt text}{250}{}{https://sites.google.com/berkeley.edu/distributed-interaction/}
[https://arxiv.org/abs/2310.01614 Distributed Multi-agent Interaction Generation with Imagined Potential Games]\n
*Lingfeng Sun*, Pin-Yun Hung, Changhao Wang, Masayoshi Tomizuka, Zhuo Xu\n
/ACC 2024/ \n
[https://sites.google.com/berkeley.edu/distributed-interaction/ \[Website\]]
[https://arxiv.org/abs/2310.01614 \[Paper]]
~~~

~~~
{}{img_left}{imgs/routegan.png}{alt text}{250}{}{https://arxiv.org/abs/2103.00906/}
[https://arxiv.org/abs/2103.00906/ Diverse Critical Interaction Generation for Planning and Planner Evaluation]\n
*Lingfeng Sun\**, Zhao-Heng Yin\*, Liting Sun, Masayoshi Tomizuka, Wei Zhan\n
/IROS 2021/ \n
[https://ieeexplore.ieee.org/abstract/document/8917031 \[Paper]]
~~~

{{</div>}}

~~~
{}{raw}
<h3 class="collapsible"> Grasp Planning [-]</h3>
<div class="content" style="display:block;">
~~~

~~~
{}{img_left}{imgs/place_oriented.png}{alt text}{250}{}{https://arxiv.org/abs/2304.01290}
[https://arxiv.org/abs/2304.01290 A Simple Approach for General Task-Oriented Picking using Placing constraints]\n
*Lingfeng Sun\**, Jen-Wei Wang\*,  Xinghao Zhu, Qiyang Qian, Masayoshi Tomizuka\n
/Preprint/
[https://arxiv.org/abs/2304.01290 \[Paper]]
~~~

~~~
{}{img_left}{imgs/cgpn.gif}{alt text}{250}{}{https://arxiv.org/pdf/2103.15995}
[https://arxiv.org/pdf/2103.15995 6-dof contrastive grasp proposal network]\n
*Lingfeng Sun\**, Xinghao Zhu\*, Yongxiang Fan, Masayoshi Tomizuka\n
/ICRA 2021/
[https://arxiv.org/pdf/2103.15995 \[Paper]]
~~~

~~~
{}{img_left}{imgs/mlgsl.gif}{alt text}{250}{}{https://arxiv.org/pdf/2110.01379 }
[https://arxiv.org/pdf/2110.01379 Learn to grasp with less supervision: A data-efficient maximum likelihood grasp sampling loss]\n
Xinghao Zhu, Yefan Zhou, Yongxiang Fan, *Lingfeng Sun*, Jianyu Chen, Masayoshi Tomizuka\n
/ICRA 2022/
[https://arxiv.org/pdf/2110.01379  \[Paper]]
~~~

{{</div>}}

~~~
{}{raw}
<h3 class="collapsible"> Behavior Prediction [-]</h3>
<div class="content" style="display:block;">
~~~

~~~
{}{img_left}{imgs/pseudo.png}{alt text}{250}{}{https://arxiv.org/pdf/2203.15112}
[https://arxiv.org/pdf/2203.15112 Domain knowledge driven pseudo labels for interpretable goal-conditioned interactive trajectory prediction]\n
   *Lingfeng Sun\**, Chen Tang\*, Yaru Niu, Enna Sachdeva, Chiho Choi, Teruhisa Misu, Masayoshi Tomizuka, Wei Zhan\n
/IROS 2022/ \n
[https://arxiv.org/pdf/2203.15112 \[Paper]]
~~~

~~~
{}{img_left}{imgs/pretram.png}{alt text}{250}{}{https://arxiv.org/pdf/2204.10435}
[https://arxiv.org/pdf/2204.10435 Pretram: Self-supervised pre-training via connecting trajectory and map]\n
   Chenfeng Xu, Tian Li, Chen Tang, *Lingfeng Sun*, Kurt Keutzer, Masayoshi Tomizuka, Alireza Fathi, Wei Zhan \n
/ECCV 2022/ \n
[https://arxiv.org/pdf/2204.10435 \[Paper]]
~~~

~~~
{}{img_left}{imgs/prediction-DBN.webp}{alt text}{250}{}{https://ieeexplore.ieee.org/abstract/document/8917031}
[https://ieeexplore.ieee.org/abstract/document/8917031 Interactive prediction for multiple, heterogeneous traffic participants with multi-agent hybrid dynamic bayesian network]\n
*Lingfeng Sun*, Wei Zhan, Di Wang, Masayoshi Tomizuka\n
/ITSC 2019/ \n
[https://ieeexplore.ieee.org/abstract/document/8917031 \[Paper]]
~~~

{{</div>}}

~~~
{}{raw}
<script>
var coll = document.getElementsByClassName("collapsible");
for (var i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block" || content.style.display === "") {
      content.style.display = "none";
      this.innerHTML = this.innerHTML.replace("[-]", "[+]");
    } else {
      content.style.display = "block";
      this.innerHTML = this.innerHTML.replace("[+]", "[-]");
    }
  });
}
</script>
~~~